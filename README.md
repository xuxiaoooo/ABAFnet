# ABAFnet
A Novel Attention-Based Acoustic Feature Fusion Network Approach for Efficient Depression Detection and Analysis

---

## ğŸ“Œ Introduction

This repository contains the implementation of our proposed **ABAFnet**, a novel integrated speech feature attention-based recurrent network for efficient depression detection and analysis. The main goal of this project is to provide an accurate and efficient approach for detecting depression using speech data.

_**Note:** The code we released is not fully final in some details, some parts are debug versions of the code, just the model structure parts are correct. Due to our concern about data privacy, we have hidden the loading part about the data, please contact us by email if you need._

- `test.py` predict image features.
- `HSFs.py` predict num vector features.
- `opensmile.py` use opensmile tool.
- `pre.py` extract image features.
- `fusion.py` fusion model.
- `compare.py` model performance comparation.
- `validation.py` load model and validate on other datasets.

---

## ğŸ’¡ Features
- Feature extraction from speech data.
- Attention mechanism for better feature representation.
- Recurrent network architecture for modeling temporal information.
- Efficient and accurate depression detection.

---

## ğŸ› ï¸ Installation and Usage
**Clone the repository**
```bash
git clone https://github.com/xuxiaoooo/ABAFnet.git
cd ISFARNet
```
---

## ğŸ“Š Results

Our proposed ABAFnet achieved state-of-the-art performance in depression detection with multi features. Detailed results and comparison with other methods can be found in our paper.

---

## ğŸ“„ Citation

If you find this work helpful, please cite our paper:
```@inproceedings{author2023isfarnet,
  title={A Novel Attention-Based Acoustic Feature Fusion Network Approach for Efficient Depression Detection and Analysis},
  author={Author, A. and Coauthor, B.},
  booktitle={Conference Name},
  year={2023}
}
```

---

## ğŸ“§ Contact

For any questions, feel free to open an issue or contact us at xuxiaooo1111@gmail.com

---
